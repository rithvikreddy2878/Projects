# -*- coding: utf-8 -*-
"""M4_Hackathon_54 (4).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_zM6wtQDx7UUcWp_FZv5kA8O6FVBnbDQ

# Loan Default Prediction 
SuperLender is a local digital lending company. SuperLender wants to build machine learning model to lower the risk of loan default and deliver profitable and high-impact loan alternative. Now, try to predict if a loan was good or bad. This is binary classification business problem, where Good is 1 and Bad is 0.
Source : https://zindi.africa/competitions/data-science-nigeria-challenge-1-loan-default-prediction

We are not given the relative impact of false negatives (versus other outcomes). You are free to make your own assumptions.

#Columns, Description 

## **a) Demographic data (traindemographics.csv)**
- **customerid** (Primary key used to merge to other data)
- **birthdate** (date of birth of the customer)
- **bank_account_type** (type of primary bank account)
- **longitude_gps**
- **latitude_gps**
- **bank_name_clients** (name of the bank)
- **bank_branch_clients** (location of the branch - not compulsory - so missing in a lot of the cases)
- **employment_status_clients** (type of employment that customer has)
- **level_of_education_clients** (highest level of education)

## **b) Performance data (trainperf.csv)**
- **customerid** (Primary key used to merge to other data)
-**systemloanid** (The id associated with the particular loan. The same customerId can have multiple systemloanidâ€™s for each loan he/she has taken out)
- **loannumber** (The number of the loan that you have to predict)
- **approveddate** (Date that loan was approved)
- **creationdate** (Date that loan application was created)
- **loanamount** (Loan value taken)
- **totaldue** (Total repayment required to settle the loan - this is the capital loan value disbursed +interest and fees)
- **termdays** (Term of loan)
- **referredby** (customerId of the customer that referred this person - is missing, then not referred)
- **good_bad_flag** (good = settled loan on time; bad = did not settled loan on time) - this is the target variable that we need to predict
"""

# Basic Libraries
import pandas as pd
import seaborn as sns

import numpy as np
from numpy import mean
from numpy import std

import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from scipy.stats.mstats import winsorize
import scipy.stats as ss
import math
import seaborn as sns
from datetime import datetime

# Scikit learn
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Perceptron
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import make_pipeline
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import roc_auc_score
from sklearn.metrics import log_loss
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.model_selection import cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.model_selection import KFold
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.model_selection import learning_curve
from sklearn.model_selection import GridSearchCV

from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as imbpipeline

"""# **Read Dataset**"""

# Read two files 
file_1 = "trainperf.csv"   # adapt this as needed to the file structure on your Google drive
df1 = pd.read_csv(file_1) # read in csv file

file_2= "traindemographics.csv"   
df2 = pd.read_csv(file_2) # read in csv file

# Merge two files using inner join
result = pd.merge(df1, df2, how='inner', on='customerid')

"""# **EDA**"""

result.tail()

# customer ID and System ID are deleted, as they don't add information to the model
# bank_branch_clients is deleted to reduce the # of features after encoding
# approveddate and creationdate are deleted, as they don't add much value 
result = result.drop(columns=['customerid', 'systemloanid','bank_branch_clients','approveddate','creationdate'])

# Shape of df
print("Shape", result.shape)

# Check data types
print(result.info())

# Describe Dataset 
print("\n DESCRIBE\n",result.describe())

# Check Skewness
print("\n SKEWNESS\n",result.skew())

# Check Skewness
print("\n kurtosis\n",result.kurtosis())

# Multivariate numerical descriptive statistics

#Correlation Matrix
print("CORRELATION MATRIX\n",result.corr())
print("\n\n")

#Correlation Matrix as a Heatmap
sns.set_style('darkgrid')
plt.figure(figsize = (10,5))
cmap = sns.diverging_palette(120, 10, l = 40, s = 99, sep = 20, center = 'light', as_cmap = True) 
sns.heatmap((result).corr(), vmin = -1, vmax = 1, annot = True, cmap = cmap, lw = .5, linecolor = 'white')
plt.title("Dataset Correlation Heatmap")
plt.show()

# Covariance Matrix
print("\n\nCOVARIANCE MATRIX\n",result.cov())
print("\n\n")

#Covariance Matrix as a Heatmap
sns.set_style('darkgrid')
plt.figure(figsize = (10,5))
cmap = sns.diverging_palette(220, 20, l = 40, s = 99, sep = 20, center = 'light', as_cmap = True) 
sns.heatmap((result).cov(), vmin = -0.5, vmax = 3.5, annot = True, cmap = cmap, lw = .5, linecolor = 'white')
plt.title("Dataset Covariance Heatmap")
plt.show()

"""#**Encoding**"""

# Encode categorical target variable 
good_bad_flag_mapping = {'Good': 1,
                         'Bad' : 0}
result['good_bad_flag'] = result['good_bad_flag'].map(good_bad_flag_mapping)
print('Label-encoded good_bad_flag:\n',result,"\n\n")

# Count good and bad 
result["good_bad_flag"].value_counts().plot.bar()
result["good_bad_flag"].value_counts()

# rename less frequent categories of bank_name_clients to 'Other'
need = result['bank_name_clients'].value_counts().index[:2]
result['bank_name_clients'] = np.where(result['bank_name_clients'].isin(need), result['bank_name_clients'], 'OTHER')

valCount = result['bank_name_clients'].value_counts()
print (valCount)

# Univariate Bar Charts

plt.figure(figsize = (30,6))
plt.subplot(1,2,1)
sns.countplot(  x="bank_name_clients", data=result,palette="light:m_r",
    edgecolor=".3")
plt.show()

# rename less frequent categories of employment_status_clients to 'Other'
need = result['employment_status_clients'].value_counts().index[:3]
result['employment_status_clients'] = np.where(result['employment_status_clients'].isin(need), result['employment_status_clients'], 'OTHER')

valCount = result['employment_status_clients'].value_counts()
print (valCount)

# Univariate Bar Charts

plt.figure(figsize = (30,6))
plt.subplot(1,2,2)
sns.countplot(  x="employment_status_clients", data=result,palette="light:m_r",
    edgecolor=".3")
plt.show()

# Univariate Bar Charts

plt.figure(figsize = (30,6))
plt.subplot(1,2,2)
sns.countplot(  x="level_of_education_clients", data=result,palette="light:m_r",
    edgecolor=".3")
plt.show()

# Univariate Bar Charts

plt.figure(figsize = (30,6))
plt.subplot(1,2,2)
sns.countplot(  x="bank_account_type", data=result,palette="light:m_r",
    edgecolor=".3")
plt.show()

# change birthday to age. New column age is created
import pandas as pd
from datetime import datetime, date

  
# This function converts given date to age
def age(born):
    born = datetime.strptime(born, '%Y-%m-%d %H:%M:%S.%f').date()
    today = date.today()
    return today.year - born.year - ((today.month, 
                                      today.day) < (born.month, 
                                                    born.day))
  
result['Age'] = result['birthdate'].apply(age)
  
display(result)

# drop birthday
result = result.drop(columns=['birthdate'])

# Agglomerative Clustering
from sklearn.cluster import AgglomerativeClustering
model = AgglomerativeClustering(n_clusters=6)
model.fit(result[['longitude_gps','latitude_gps']])
# assign a cluster to each example
yhat = pd.DataFrame(model.fit_predict(result[['longitude_gps','latitude_gps']]),columns=['Location_Cluster'])
if 'Location_Cluster' not in result:
  result = pd.concat([result,yhat],axis=1)
else:
  result['Location_Cluster'] = yhat
colors = ['#747FE3', '#8EE35D', '#E37346']
sns.set_palette(sns.color_palette(colors))
sns.scatterplot(x='longitude_gps', y='latitude_gps', data=result, hue='Location_Cluster', palette = "brg")

# transform referredby variable to binary category 
# df["referredby"].fillna(np.nan, inplace = "No") 
for index, row in result.iterrows():
  if(pd.isnull(row['referredby'])):
    result['referredby'][index] = "No"
  else:
    result['referredby'][index] = "Yes"

# Univariate Bar Charts

plt.figure(figsize = (30,6))
plt.subplot(1,2,2)
sns.countplot(  x="referredby", data=result,palette="light:m_r",
    edgecolor=".3")
plt.show()

# create dummy variables for categorical variables 
result = pd.get_dummies(data=result, columns=['referredby','bank_name_clients','employment_status_clients','bank_account_type','level_of_education_clients'])

result

"""#**Visualizations**"""

# Violinplots for quant variables
result["All"] = ""
for i in result.columns:
  if (result.dtypes[i] == 'int64' or result.dtypes[i] == 'float64') and ((i != 'All') and (i != 'good_bad_flag')):
    plt.figure(figsize = (10,5))
    sns.violinplot(x = 'All',y = i, hue = "good_bad_flag", data = result,palette = {True:'blue', False:'red'})
    plt.show()
result.drop('All',axis=1)

result = result.drop(columns=['All'])

# Bivariate violinplots
plt.figure(figsize = (10,5))
sns.violinplot(x ="termdays", y ="totaldue", hue ="good_bad_flag",data = result, split = True)
plt.show()
plt.figure(figsize = (10,5))
sns.violinplot(x ="loanamount", y ="totaldue", hue ="good_bad_flag",data = result, split = True)
plt.show()

"""# **Missing values & duplicates**"""

# Count total NaN at each column in a DataFrame
print(" \nCount total NaN at each column in a DataFrame : \n\n",
      result.isnull().sum())

result.isnull().any()

# Check for duplicates and remove if there is any 
result.drop_duplicates(inplace = True)
print('\n Duplicates\n',result.duplicated().sum())

"""#**Pre-processing - Skewness correction**"""

# pick numerical variables and set them as X
X = result[['loanamount','totaldue','termdays','loannumber','longitude_gps','latitude_gps','Age']]

# Code for skewness correction (see source below)
# Depending upon the characteritics of a feature (column), a log, Box-Cox or power transform is applied to normalize the distribution 

# -*- coding: utf-8 -*-
"""
Created on Sat Feb 23 14:42:46 2019
@author: DATAmadness
"""

##################################################
# A function that will accept a pandas dataframe
# and auto-transforms columns that exceeds threshold value
#  -  Offers choice between boxcox or log / exponential transformation
#  -  Automatically handles negative values
#  -  Auto recognizes positive /negative skewness

# Further documentation available here:
# https://datamadness.github.io/Skewness_Auto_Transform

def skew_autotransform(DF, include = None, exclude = None, plot = False, threshold = 1, exp = False):
    
    #Get list of column names that should be processed based on input parameters
    if include is None and exclude is None:
        colnames = DF.columns.values
    elif include is not None:
        colnames = include
    elif exclude is not None:
        colnames = [item for item in list(DF.columns.values) if item not in exclude]
    else:
        print('No columns to process!')
    
    #Helper function that checks if all values are positive
    def make_positive(series):
        minimum = np.amin(series)
        #If minimum is negative, offset all values by a constant to move all values to positive teritory
        if minimum <= 0:
            series = series + abs(minimum) + 0.01
        return series
    
    
    #Go through desired columns in DataFrame
    for col in colnames:
        #Get column skewness
        skew = DF[col].skew()
        transformed = True
        
        if plot:
            #Prep the plot of original data
            sns.set_style("darkgrid")
            sns.set_palette("Blues_r")
            fig, axes = plt.subplots(1, 2, figsize=(10, 5))
            #ax1 = sns.distplot(DF[col], ax=axes[0])
            ax1 = sns.histplot(DF[col], ax=axes[0], color="blue", label="100% Equities", kde=True, stat="density", linewidth=0)
            ax1.set(xlabel='Original ' + str(col))
        
        #If skewness is larger than threshold and positively skewed; If yes, apply appropriate transformation
        if abs(skew) > threshold and skew > 0:
            skewType = 'positive'
            #Make sure all values are positive
            DF[col] = make_positive(DF[col])
            
            if exp:
               #Apply log transformation 
               DF[col] = DF[col].apply(math.log)
            else:
                #Apply boxcox transformation
                DF[col] = ss.boxcox(DF[col])[0]
            skew_new = DF[col].skew()
         
        elif abs(skew) > threshold and skew < 0:
            skewType = 'negative'
            #Make sure all values are positive
            DF[col] = make_positive(DF[col])
            
            if exp:
               #Apply exp transformation 
               DF[col] = DF[col].pow(10)
            else:
                #Apply boxcox transformation
                DF[col] = ss.boxcox(DF[col])[0]
            skew_new = DF[col].skew()
        
        else:
            #Flag if no transformation was performed
            transformed = False
            skew_new = skew
        
        #Compare before and after if plot is True
        if plot:
            print('\n ------------------------------------------------------')     
            if transformed:
                print('\n %r had %r skewness of %2.2f' %(col, skewType, skew))
                print('\n Transformation yielded skewness of %2.2f' %(skew_new))
                sns.set_palette("Paired")
                #ax2 = sns.distplot(DF[col], ax=axes[1], color = 'r')
                ax2 = sns.histplot(DF[col], ax=axes[1], color="red", label="100% Equities", kde=True, stat="density", linewidth=0)
                ax2.set(xlabel='Transformed ' + str(col))
                plt.show()
            else:
                print('\n NO TRANSFORMATION APPLIED FOR %r . Skewness = %2.2f' %(col, skew))
                #ax2 = sns.distplot(DF[col], ax=axes[1])
                ax2 = sns.histplot(DF[col], ax=axes[1], color="blue", label="100% Equities", kde=True, stat="density", linewidth=0)
                ax2.set(xlabel='NO TRANSFORM ' + str(col))
                plt.show()
                

    return DF

# Use code above (adapted from https://github.com/datamadness/Automatic-skewness-transformation-for-Pandas-DataFrame) to correct skewness
# All the predictors are real-valued, so we can push them all through the skewness check/correction.
X = skew_autotransform(X.copy(deep=True), plot = True, exp = False, threshold = 1)

"""#**Pre-processing - Outliers**"""

# Tukey Rule outliers
# As an alternative, you could use z-scores greater than 3 or less than -3.

cols = X.columns
#Tukey's method
def tukey_rule(data, col):
    Q1 = data[col].quantile(0.25)
    Q3 = data[col].quantile(0.75)
    IQR = Q3 - Q1
    upper_lim = data[col].quantile(0.5) + 2 * IQR
    lower_lim = data[col].quantile(0.5) - 2 * IQR
    outliers = []
    for index, x in enumerate(data[col]):
        if x < lower_lim or x >= upper_lim:
            outliers.append(index)
    return outliers

# Identify outliers
for i in cols:
  outliers_Tukey = tukey_rule(X,i)
  print("Column ",i,": ",outliers_Tukey)
  
# Windsorize X and check the results
print("Before", X.describe())
X_winsorized = X.copy(deep=True)
for i in cols:
  X_winsorized[i] = winsorize(X[i], limits=(0.05, 0.05))
print("After", X_winsorized.describe())

#Review columns
result.columns

X = result.drop(['good_bad_flag'], axis=1)
y = result['good_bad_flag']

# split train and test data manually

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print('Training Data Predictors\n',X_train.head(), '\nTraining Data Target\n',y_train.head(),'\n')
print('Test Data Predictors\n',X_test.head(), '\nTest Data Target\n',y_test.head())

# Standardization of predictor
stdsc = StandardScaler()  
X_train_std = stdsc.fit_transform(X_train)   
X_test_std = stdsc.transform(X_test)            # transform uses the parameters from scaling the training data to transform our test data

# Classifier decision regions on unbalanced holdout sample
names = ["Perceptron", "Logistic Regression", "SVM (RBF kernel)", "Decision Tree", "Naive Bayes", "k Nearest Neighbors", "MLP", "Random Forest", "XG Boost", "Light GBM"]

classifiers = [
    Perceptron(random_state=1),    
    LogisticRegression(),   
    SVC(kernel="rbf", C=1),
    DecisionTreeClassifier(max_depth=5),
    GaussianNB(),
    KNeighborsClassifier(3),
    MLPClassifier(hidden_layer_sizes=(50,50),alpha=1, max_iter=1000),
    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),
    XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, n_estimators=100, max_depth=3),
    LGBMClassifier(boosting_type='gbdt', objective='binary', num_leaves=50, learning_rate=0.1, bagging_fraction=0.9, feature_fraction=0.9, reg_lambda=0.2)]

# we use precision as the metric, and apply this metric to train and test data to find out the best classifier
# logistic is the best

for name, clf in zip(names, classifiers):
  # Pipeline
  estimators = []
  estimators.append(('standardize', StandardScaler()))
  estimators.append(('classifier',clf))
  model = Pipeline(estimators)
  # Eval Pipeline
  kfold_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=11)
  scoring = ['accuracy','balanced_accuracy','precision','recall','f1','roc_auc']
  for sc in scoring:
    results = cross_val_score(model, X=X, y=y, cv=kfold_cv, scoring=sc)
    print('Classifier: %s Metric %s mean (std deviation): %.3f (%.3f)' % (name, sc, results.mean(), results.std()))
  print('\n')
  print('Classifier: %s Metric precision mean (std deviation): %.3f (%.3f)' % (name, results.mean(), results.std()))
  print('\n')

# we use precision as the metric, and apply this metric to K-fold data to find out the best classifier
# KNN and XGboost are the best

# Classifier decision regions on unbalanced holdout sample
names = ["Perceptron", "Logistic Regression", "SVM (RBF kernel)", "Decision Tree", "Naive Bayes", "k Nearest Neighbors", "MLP", "Random Forest", "XG Boost", "Light GBM"]

classifiers = [
    Perceptron(random_state=1),    
    LogisticRegression(),   
    SVC(kernel="rbf", C=1),
    DecisionTreeClassifier(max_depth=5),
    GaussianNB(),
    KNeighborsClassifier(3),
    MLPClassifier(hidden_layer_sizes=(50,50),alpha=1, max_iter=1000),
    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),
    XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, n_estimators=100, max_depth=3),
    LGBMClassifier(boosting_type='gbdt', objective='binary', num_leaves=50, learning_rate=0.1, bagging_fraction=0.9, feature_fraction=0.9, reg_lambda=0.2)]

no_folds = 5 # number of folds desired for cross validation
kf = StratifiedKFold(n_splits=no_folds, shuffle=True, random_state=12345)
for name, clf in zip(names, classifiers):
  print('CLASSIFIER: ',name,'\n')
  mean_accuracy = 0.0
  mean_balanced_accuracy = 0.0
  mean_auc = 0.0
  mean_precision = 0.0
  for fold, (train_index, test_index) in enumerate(kf.split(X,y),1):
    X_train, X_test = X.iloc[list(train_index)], X.iloc[list(test_index)]
    y_train, y_test = y.iloc[list(train_index)], y.iloc[list(test_index)] 
    sm = SMOTE()
    X_train_SMOTE, y_train_SMOTE = sm.fit_resample(X_train, y_train)
    stdsc = StandardScaler()  
    X_train_SMOTE_std = stdsc.fit_transform(X_train_SMOTE)   
    X_test_std = stdsc.transform(X_test)   
    clf.fit(X_train_SMOTE_std, y_train_SMOTE) 
    y_pred = clf.predict(X_test_std)
    print(f'For fold {fold}:')
    print(f'precision: {precision_score(y_test, y_pred)}')
    mean_balanced_accuracy = mean_balanced_accuracy + balanced_accuracy_score(y_test, y_pred)
    mean_auc = mean_auc + roc_auc_score(y_test, y_pred)
    mean_precision = mean_precision + precision_score(y_test, y_pred)
  mean_precision = mean_precision / no_folds
  print('Average precision: %.3f' % (mean_precision))

# apply PCA on train_data to get important features --not working

from sklearn.decomposition import PCA

pca = PCA()
X_pca = pca.fit_transform(X_train_SMOTE)
pca.explained_variance_ratio_

# Show the explained variance ratio in order for each components
plt.bar(range(1, 15), pca.explained_variance_ratio_[:14], alpha=0.3, align='center')
plt.step(range(1, 15), np.cumsum(pca.explained_variance_ratio_[:14]), where='mid')
plt.ylabel('Explained variance ratio')
plt.xlabel('Principal components')
plt.show()

X_pca = pd.DataFrame(X_pca)

# the first is important, but others also have some explainatory power

# apply RFE on train_data to get important features

from sklearn.feature_selection import RFE

rfe = RFE(estimator=RandomForestClassifier(), n_features_to_select=10)
_ = rfe.fit(X_train_std, y_train)
print('Important Features\n',X.columns[rfe.support_])

# we use precision as the metric, and apply this metric to K-fold data and [selected features] to find out the best classifier
# KNN and XGboost are the best

# Classifier decision regions on unbalanced holdout sample
names = ["Perceptron", "Logistic Regression", "SVM (RBF kernel)", "Decision Tree", "Naive Bayes", "k Nearest Neighbors", "MLP", "Random Forest", "XG Boost", "Light GBM"]

classifiers = [
    Perceptron(random_state=1),    
    LogisticRegression(),   
    SVC(kernel="rbf", C=1),
    DecisionTreeClassifier(max_depth=5),
    GaussianNB(),
    KNeighborsClassifier(3),
    MLPClassifier(hidden_layer_sizes=(50,50),alpha=1, max_iter=1000),
    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),
    XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, n_estimators=100, max_depth=3),
    LGBMClassifier(boosting_type='gbdt', objective='binary', num_leaves=50, learning_rate=0.1, bagging_fraction=0.9, feature_fraction=0.9, reg_lambda=0.2)]

X_selected = X[['loannumber', 'loanamount', 'totaldue', 'longitude_gps', 'latitude_gps',
       'Age', 'referredby_No', 'bank_name_clients_GT Bank',
       'bank_name_clients_OTHER', 'employment_status_clients_Permanent']]

no_folds = 5 # number of folds desired for cross validation
kf = StratifiedKFold(n_splits=no_folds, shuffle=True, random_state=12345)
for name, clf in zip(names, classifiers):
  print('CLASSIFIER: ',name,'\n')
  mean_accuracy = 0.0
  mean_balanced_accuracy = 0.0
  mean_auc = 0.0
  mean_precision = 0.0
  for fold, (train_index, test_index) in enumerate(kf.split(X_selected,y),1):
    X_train, X_test = X.iloc[list(train_index)], X.iloc[list(test_index)]
    y_train, y_test = y.iloc[list(train_index)], y.iloc[list(test_index)] 
    sm = SMOTE()
    X_train_SMOTE, y_train_SMOTE = sm.fit_resample(X_train, y_train)
    stdsc = StandardScaler()  
    X_train_SMOTE_std = stdsc.fit_transform(X_train_SMOTE)   
    X_test_std = stdsc.transform(X_test)   
    clf.fit(X_train_SMOTE_std, y_train_SMOTE) 
    y_pred = clf.predict(X_test_std)
    print(f'For fold {fold}:')
    print(f'precision: {precision_score(y_test, y_pred)}')
    mean_balanced_accuracy = mean_balanced_accuracy + balanced_accuracy_score(y_test, y_pred)
    mean_auc = mean_auc + roc_auc_score(y_test, y_pred)
    mean_precision = mean_precision + precision_score(y_test, y_pred)
  mean_precision = mean_precision / no_folds
  print('Average precision: %.3f' % (mean_precision))

# find the best KNN model hyper parameters using all features

model = imbpipeline([
        ('sample', SMOTE()),
        ('std', StandardScaler()),
        ('clf', KNeighborsClassifier())])

param_grid = {'clf__n_neighbors': [19, 21, 23],
              'clf__metric': ['minkowski', 'euclidean', 'manhattan']}
grid = GridSearchCV(estimator=model, param_grid=param_grid, cv = 5, scoring = 'average_precision')
grid.fit(X, y)
print(grid.best_params_)
print(grid.best_estimator_)

# best n_neighbors is 21

"""# BLUF:
- We used PCA and RFE to find the best predictors. RFE provides more useful insights
- using the filtered features, we split training and testing data with k-fold
- using presicion score as the key metric, we found the best classifiers are KNN and XGBoost
- using grid method, we found the best hyper parameters for KNN is minkowski distance and 21 neighbors
"""